{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Query Refinement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Refined Query: Query: What are the potential physical and psychological impacts caused by chronic stress?\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "\n",
    "def refine_query(query):\n",
    "    client = openai.OpenAI()  # Create an OpenAI client instance\n",
    "    \n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"Improve retrieval-focused queries.\"},\n",
    "            {\"role\": \"user\", \"content\": f\"Refine the following query to focus on causal reasoning:\\nQuery: {query}\"}\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message.content  # Corrected way to access the response\n",
    "\n",
    "# Example Usage\n",
    "raw_query = \"What are the effects of chronic stress?\"\n",
    "refined_query = refine_query(raw_query)\n",
    "print(\"Refined Query:\", refined_query)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "-----------------------------\n",
      "| time/              |      |\n",
      "|    fps             | 2612 |\n",
      "|    iterations      | 1    |\n",
      "|    time_elapsed    | 0    |\n",
      "|    total_timesteps | 2048 |\n",
      "-----------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.ppo.ppo.PPO at 0x7e11dc5019a0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "from stable_baselines3 import PPO\n",
    "\n",
    "class QueryRefinementEnv(gym.Env):\n",
    "    def __init__(self, causal_graph):\n",
    "        super(QueryRefinementEnv, self).__init__()\n",
    "        self.causal_graph = causal_graph\n",
    "        self.action_space = gym.spaces.Discrete(3)  # Actions: Expand, Simplify, Decompose\n",
    "        self.observation_space = gym.spaces.Box(low=0, high=1, shape=(1,), dtype=np.float32)  # Sample observation space\n",
    "\n",
    "    def reset(self, seed=None, options=None):\n",
    "        \"\"\"Reset the environment at the start of an episode.\"\"\"\n",
    "        super().reset(seed=seed)  # Ensure compatibility with Gymnasium\n",
    "        initial_state = np.array([0.0], dtype=np.float32)  # Example initial state\n",
    "        info = {}  # No additional info needed\n",
    "        return initial_state, info  # ✅ Must return (observation, info)\n",
    "\n",
    "    def step(self, action):\n",
    "        \"\"\"Take an action and return the new state, reward, done flag, and info.\"\"\"\n",
    "        reward = np.random.randint(1, 10)  # Placeholder reward function\n",
    "        next_state = np.array([np.random.random()], dtype=np.float32)  # Random next state\n",
    "        done = False  # Keep episode running\n",
    "        info = {}  # Additional info\n",
    "        return next_state, reward, done, False, info  # ✅ Must return (state, reward, done, truncated, info)\n",
    "\n",
    "# ✅ Initialize environment & PPO Model\n",
    "env = QueryRefinementEnv(causal_graph={})\n",
    "model = PPO(\"MlpPolicy\", env, verbose=1, device=\"cpu\")  # Use CPU for stability\n",
    "\n",
    "# ✅ Train the model\n",
    "model.learn(total_timesteps=1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "-----------------------------\n",
      "| time/              |      |\n",
      "|    fps             | 2620 |\n",
      "|    iterations      | 1    |\n",
      "|    time_elapsed    | 0    |\n",
      "|    total_timesteps | 2048 |\n",
      "-----------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1887         |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 2            |\n",
      "|    total_timesteps      | 4096         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0044086277 |\n",
      "|    clip_fraction        | 4.88e-05     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.1         |\n",
      "|    explained_variance   | -8.26e-05    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.66e+03     |\n",
      "|    n_updates            | 10           |\n",
      "|    policy_gradient_loss | -0.00251     |\n",
      "|    value_loss           | 6.33e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1727         |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 3            |\n",
      "|    total_timesteps      | 6144         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0030186917 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.09        |\n",
      "|    explained_variance   | -0.0211      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.71e+03     |\n",
      "|    n_updates            | 20           |\n",
      "|    policy_gradient_loss | -0.00167     |\n",
      "|    value_loss           | 5.98e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1659         |\n",
      "|    iterations           | 4            |\n",
      "|    time_elapsed         | 4            |\n",
      "|    total_timesteps      | 8192         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0016766607 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.09        |\n",
      "|    explained_variance   | -0.00688     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.65e+03     |\n",
      "|    n_updates            | 30           |\n",
      "|    policy_gradient_loss | -0.000999    |\n",
      "|    value_loss           | 5.82e+03     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 1620         |\n",
      "|    iterations           | 5            |\n",
      "|    time_elapsed         | 6            |\n",
      "|    total_timesteps      | 10240        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0009397622 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.1         |\n",
      "|    explained_variance   | -0.000604    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 2.7e+03      |\n",
      "|    n_updates            | 40           |\n",
      "|    policy_gradient_loss | -0.000491    |\n",
      "|    value_loss           | 5.89e+03     |\n",
      "------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.env_checker import check_env\n",
    "\n",
    "# Define the Query Refinement Environment\n",
    "class QueryRefinementEnv(gym.Env):\n",
    "    def __init__(self, causal_graph):\n",
    "        super(QueryRefinementEnv, self).__init__()\n",
    "        self.causal_graph = causal_graph\n",
    "        self.action_space = gym.spaces.Discrete(3)  # [0: Expand, 1: Simplify, 2: Decompose]\n",
    "        self.observation_space = gym.spaces.Box(low=0.0, high=1.0, shape=(1,), dtype=np.float32)\n",
    "        self.current_state = np.array([0.0], dtype=np.float32)\n",
    "\n",
    "    def reset(self, seed=None, options=None):\n",
    "        super().reset(seed=seed)\n",
    "        self.current_state = np.array([0.0], dtype=np.float32)\n",
    "        return self.current_state, {}\n",
    "\n",
    "    def step(self, action):\n",
    "        # Simulated reward function based on mock retrieval success\n",
    "        reward = np.random.randint(1, 10)  # Replace with actual reward from retrieval engine\n",
    "        self.current_state = np.array([np.random.rand()], dtype=np.float32)\n",
    "        terminated = False\n",
    "        truncated = False\n",
    "        info = {}\n",
    "        return self.current_state, reward, terminated, truncated, info\n",
    "\n",
    "# Initialize environment\n",
    "env = QueryRefinementEnv(causal_graph={})\n",
    "check_env(env)  # Optional: check environment compliance\n",
    "\n",
    "# Train PPO model\n",
    "model = PPO(\"MlpPolicy\", env, verbose=1, device=\"cpu\")  # Use CPU (recommended for MLP-based PPO)\n",
    "model.learn(total_timesteps=10000)\n",
    "\n",
    "# Save model\n",
    "model.save(\"ppo_query_refiner\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Refined Query: Refined Query: What causes and results emerge from chronic stress conditions?\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Retrieve API key from environment variables\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# Check if the key is loaded correctly\n",
    "if api_key is None:\n",
    "    raise ValueError(\"❌ API key not found! Make sure it's set in the .env file.\")\n",
    "\n",
    "# Initialize OpenAI client\n",
    "client = openai.OpenAI(api_key=api_key)\n",
    "\n",
    "def refine_query_with_llm(query: str) -> str:\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"Refine user queries to focus on causality and improve information retrieval.\"},\n",
    "            {\"role\": \"user\", \"content\": f\"Refine the following query for better causal retrieval:\\n\\nQuery: {query}\"}\n",
    "        ]\n",
    "    )\n",
    "    return response.choices[0].message.content.strip()\n",
    "\n",
    "# Example usage\n",
    "query = \"What are the effects of chronic stress?\"\n",
    "refined_query = refine_query_with_llm(query)\n",
    "print(\"Refined Query:\", refined_query)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Refined Query: Refined Query: How does stress cause health problems?\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Retrieve API key from environment variables\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# Check if the key is loaded correctly\n",
    "if api_key is None:\n",
    "    raise ValueError(\"❌ API key not found! Make sure it's set in the .env file.\")\n",
    "\n",
    "# Initialize OpenAI client\n",
    "client = openai.OpenAI(api_key=api_key)\n",
    "\n",
    "def refine_query_with_llm(query: str) -> str:\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"Refine user queries to focus on causality and improve information retrieval.\"},\n",
    "            {\"role\": \"user\", \"content\": f\"Refine the following query for better causal retrieval:\\n\\nQuery: {query}\"}\n",
    "        ]\n",
    "    )\n",
    "    return response.choices[0].message.content.strip()\n",
    "\n",
    "# Example usage\n",
    "query = \"Stress and health\"\n",
    "refined_query = refine_query_with_llm(query)\n",
    "print(\"Refined Query:\", refined_query)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RL Agent Suggested Action: 1\n"
     ]
    }
   ],
   "source": [
    "from stable_baselines3 import PPO\n",
    "\n",
    "# Load trained model\n",
    "model = PPO.load(\"ppo_query_refiner\")\n",
    "\n",
    "# Simulate a query refinement action\n",
    "env = QueryRefinementEnv(causal_graph={})\n",
    "obs, _ = env.reset()\n",
    "action, _ = model.predict(obs, deterministic=True)\n",
    "print(\"RL Agent Suggested Action:\", action)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Suggested refinement: Simplify Query\n"
     ]
    }
   ],
   "source": [
    "from stable_baselines3 import PPO\n",
    "\n",
    "# Load trained model\n",
    "model = PPO.load(\"ppo_query_refiner\")\n",
    "\n",
    "# Initialize environment\n",
    "env = QueryRefinementEnv(causal_graph={})\n",
    "\n",
    "# Reset environment and get initial observation\n",
    "obs, _ = env.reset()\n",
    "\n",
    "# Predict refinement action\n",
    "action, _ = model.predict(obs, deterministic=True)\n",
    "\n",
    "# Action mapping\n",
    "action_map = {0: \"Expand Query\", 1: \"Simplify Query\", 2: \"Decompose Query\"}\n",
    "print(\"Suggested refinement:\", action_map[int(action)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neo4j Driver is working!\n"
     ]
    }
   ],
   "source": [
    "from neo4j import GraphDatabase\n",
    "print(\"Neo4j Driver is working!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/hao/anaconda3/envs/colm/lib/python3.9/site-packages/neo4j/__init__.py\n"
     ]
    }
   ],
   "source": [
    "import neo4j\n",
    "print(neo4j.__file__)  # This should print the correct install path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.28.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_135544/2553396769.py:1: DeprecationWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html\n",
      "  import pkg_resources\n"
     ]
    }
   ],
   "source": [
    "import pkg_resources\n",
    "print(pkg_resources.get_distribution(\"neo4j\").version)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "colm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
